{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#$env:BEA_USERID = \"C7AB3527-B334-4396-B1C9-837FAF4FB814\"\n",
        "import os\n",
        "os.environ[\"BEA_USERID\"] = \"C7AB3527-B334-4396-B1C9-837FAF4FB814\""
      ],
      "metadata": {
        "id": "kp-Bf-j4AHqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional\n",
        "import os, json, math, time, logging\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from scipy import stats\n",
        "import altair as alt"
      ],
      "metadata": {
        "id": "WI_BPl6fBBXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bea_sector_analysis.py\n",
        "\"\"\"\n",
        "import os, json, math, time, logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from scipy import stats\n",
        "\"\"\"\n",
        "# --- config ---\n",
        "BEA_USERID = os.getenv(\"BEA_USERID\")  # REQUIRED\n",
        "OUTPUT_DIR = Path(\"dashboard_output\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "HIST_YEARS = list(range(2010, 2017))  # 2010-2016\n",
        "RISK_FREE = 0.0175\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\n",
        "\n",
        "# -----------------------------\n",
        "# 1) BEA helper: get data\n",
        "# -----------------------------\n",
        "BEA_BASE = \"https://apps.bea.gov/api/data\"\n",
        "\n",
        "def bea_get_data(dataset: str, tableid: str, year_from: int, year_to: int, freq=\"A\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Uses BEA API to get Data for a table. Must know TableID (use GetParameterValues to discover).\n",
        "    Returns DataFrame with Year, IndustryCode (or LineDescription), DataValue.\n",
        "    \"\"\"\n",
        "    if not BEA_USERID:\n",
        "        raise RuntimeError(\"Set BEA_USERID environment variable (see https://apps.bea.gov/api/signup/).\")\n",
        "    params = {\n",
        "        \"UserID\": BEA_USERID,\n",
        "        \"method\": \"GetData\",\n",
        "        \"DataSetName\": dataset,     # e.g., \"GDPbyIndustry\"\n",
        "        \"TableID\": tableid,         # e.g., \"XX\" — must be looked up\n",
        "        \"Frequency\": freq,\n",
        "        \"Year\": f\"{year_from}-{year_to}\",\n",
        "        \"ResultFormat\": \"JSON\"\n",
        "    }\n",
        "    r = requests.get(BEA_BASE, params=params, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    j = r.json()\n",
        "    data = j[\"BEAAPI\"][\"Results\"][\"Data\"]\n",
        "    df = pd.DataFrame(data)\n",
        "    # normalize columns\n",
        "    if \"DataValue\" in df.columns:\n",
        "        df[\"DataValue\"] = pd.to_numeric(df[\"DataValue\"], errors=\"coerce\")\n",
        "    if \"TimePeriod\" in df.columns:\n",
        "        df[\"Year\"] = df[\"TimePeriod\"].astype(int)\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Company financials & ROCE\n",
        "# -----------------------------\n",
        "def fetch_financials_yf(ticker: str, years: List[int]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Tries to fetch annual income and balance sheet from yfinance.\n",
        "    yfinance returns yearly frames keyed by periods; we'll attempt to pull \"Operating Income\" (or EBIT) and\n",
        "    assets/current liabilities to compute ROCE for available years.\n",
        "    Returns DataFrame indexed by Year with columns EBIT, TotalAssets, CurrentLiabilities.\n",
        "    \"\"\"\n",
        "    tk = yf.Ticker(ticker)\n",
        "    # yfinance may expose .financials (quarterly) and .get_financials? We'll attempt .financials / .balance_sheet / .cashflow\n",
        "    try:\n",
        "        # annual stat: use 'financials' & 'balance_sheet' which are quarterly by default in yfinance,\n",
        "        # but Ticker has attribute .get_financials? We'll use the .financials (columns = years)\n",
        "        inc = tk.financials.transpose()  # columns: items like 'Total Revenue', index: periods\n",
        "    except Exception:\n",
        "        inc = pd.DataFrame()\n",
        "    try:\n",
        "        bal = tk.balance_sheet.transpose()\n",
        "    except Exception:\n",
        "        bal = pd.DataFrame()\n",
        "    # Normalize year index (yfinance gives Timestamp index); parse year\n",
        "    def normalize(df):\n",
        "        if df is None or df.empty:\n",
        "            return pd.DataFrame()\n",
        "        if isinstance(df.index, pd.DatetimeIndex):\n",
        "            df_out = df.copy()\n",
        "            df_out.index = df_out.index.year\n",
        "            return df_out\n",
        "        else:\n",
        "            return df\n",
        "    inc = normalize(inc)\n",
        "    bal = normalize(bal)\n",
        "\n",
        "    rows = []\n",
        "    for y in years:\n",
        "        row = {\"Year\": y}\n",
        "        if y in inc.index:\n",
        "            # Operating Income or EBIT? Try 'Operating Income' then 'Ebit'\n",
        "            ebit = None\n",
        "            for k in [\"Operating Income\", \"OperatingIncome\", \"Ebit\", \"Earnings Before Interest and Taxes\", \"OperatingIncomeLoss\"]:\n",
        "                if k in inc.columns:\n",
        "                    ebit = inc.loc[y, k]\n",
        "                    break\n",
        "            # fallback to 'Net Income' (less ideal)\n",
        "            if ebit is None and \"Net Income\" in inc.columns:\n",
        "                ebit = inc.loc[y, \"Net Income\"]\n",
        "            row[\"EBIT\"] = float(ebit) if pd.notnull(ebit) else None\n",
        "        else:\n",
        "            row[\"EBIT\"] = None\n",
        "\n",
        "        if y in bal.index:\n",
        "            ta = bal.loc[y].get(\"Total Assets\") if \"Total Assets\" in bal.columns else None\n",
        "            cl = bal.loc[y].get(\"Total Current Liabilities\") if \"Total Current Liabilities\" in bal.columns else None\n",
        "            # yfinance uses different labels; try common alternatives\n",
        "            if ta is None:\n",
        "                for alt in [\"TotalAssets\", \"Assets\"]:\n",
        "                    if alt in bal.columns:\n",
        "                        ta = bal.loc[y, alt]\n",
        "                        break\n",
        "            if cl is None:\n",
        "                for alt in [\"Total Current Liabilities\", \"CurrentLiabilities\", \"TotalCurrentLiabilities\"]:\n",
        "                    if alt in bal.columns:\n",
        "                        cl = bal.loc[y, alt]\n",
        "                        break\n",
        "            row[\"TotalAssets\"] = float(ta) if pd.notnull(ta) else None\n",
        "            row[\"CurrentLiabilities\"] = float(cl) if pd.notnull(cl) else None\n",
        "        else:\n",
        "            row[\"TotalAssets\"] = None\n",
        "            row[\"CurrentLiabilities\"] = None\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows).set_index(\"Year\")\n",
        "\n",
        "def compute_roce_from_financials(fin_df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    ROCE = EBIT / (TotalAssets - CurrentLiabilities)\n",
        "    Returns series indexed by Year (as percent)\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    for year, r in fin_df.iterrows():\n",
        "        ebit = r.get(\"EBIT\")\n",
        "        ta = r.get(\"TotalAssets\")\n",
        "        cl = r.get(\"CurrentLiabilities\")\n",
        "        if ebit is None or ta is None or cl is None:\n",
        "            out[year] = None\n",
        "            continue\n",
        "        denom = ta - cl\n",
        "        if denom == 0 or denom is None or denom <= 0:\n",
        "            out[year] = None\n",
        "            continue\n",
        "        out[year] = float(ebit) / float(denom) * 100.0  # percent\n",
        "    return pd.Series(out)\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Big-3 statistical helpers\n",
        "# -----------------------------\n",
        "def cohens_d(a, b):\n",
        "    a = np.array(a); b = np.array(b)\n",
        "    a = a[~np.isnan(a)]; b = b[~np.isnan(b)]\n",
        "    if len(a) < 2 or len(b) < 2:\n",
        "        return None\n",
        "    na, nb = len(a), len(b)\n",
        "    sa = np.std(a, ddof=1); sb = np.std(b, ddof=1)\n",
        "    pooled = math.sqrt(((na-1)*sa*sa + (nb-1)*sb*sb)/(na+nb-2)) if na+nb-2>0 else None\n",
        "    if pooled and pooled>0:\n",
        "        return float((a.mean()-b.mean())/pooled)\n",
        "    return None\n",
        "\n",
        "def bootstrap_ci_diff(a, b, iters=2000, ci=95):\n",
        "    a = np.array(a); b = np.array(b)\n",
        "    a = a[~np.isnan(a)]; b = b[~np.isnan(b)]\n",
        "    if len(a)==0 or len(b)==0:\n",
        "        return None, None, None\n",
        "    rng = np.random.default_rng(123)\n",
        "    diffs = []\n",
        "    for _ in range(iters):\n",
        "        sa = rng.choice(a, size=len(a), replace=True)\n",
        "        sb = rng.choice(b, size=len(b), replace=True)\n",
        "        diffs.append(np.mean(sa)-np.mean(sb))\n",
        "    diffs = np.array(diffs)\n",
        "    mean_diff = diffs.mean()\n",
        "    low = np.percentile(diffs, (100-ci)/2)\n",
        "    high = np.percentile(diffs, 100-(100-ci)/2)\n",
        "    return float(mean_diff), float(low), float(high)\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Example mapping of industries -> company tickers\n",
        "# -----------------------------\n",
        "INDUSTRY_COMPANIES = {\n",
        "    \"Steel\": [\"NUE\", \"X\", \"STLD\"],   # Nucor (NUE), U.S. Steel (X), Steel Dynamics (STLD)\n",
        "    \"Semiconductors\": [\"INTC\",\"QCOM\",\"TXN\"],\n",
        "    \"Pharmaceuticals\": [\"PFE\",\"JNJ\",\"MRK\"],\n",
        "    \"Tobacco\": [\"MO\", \"PM\", \"BTI\"],\n",
        "    \"Computer Software\": [\"MSFT\", \"ORCL\", \"CRM\"],\n",
        "    \"Household and Personal Care Products\": [\"PG\", \"KMB\", \"CL\"],\n",
        "    \"Semiconductors\": [\"INTC\", \"QCOM\", \"TXN\"],\n",
        "    \"Pharmaceuticals\": [\"PFE\", \"JNJ\", \"MRK\"],\n",
        "    \"Entertainment\": [\"DIS\", \"WBD\", \"PARA\"],\n",
        "    \"Aerospace and Defense\": [\"BA\", \"LMT\", \"RTX\"],\n",
        "    \"Beverages\": [\"KO\", \"STZ\", \"PEP\"],\n",
        "    \"Chemicals (Specialty)\": [\"PPG\", \"LIN\", \"BAYRY\"],\n",
        "    \"Food Processing\": [\"KHC\", \"GIS\", \"CAG\"],\n",
        "    \"Medical Products\": [\"BDX\", \"SYK\", \"BSX\"],\n",
        "    \"Engineering and Construction\": [\"FLR\", \"ACM\", \"J\"],\n",
        "    \"Restaurants and Catering\": [\"MCD\", \"DRI\", \"SBUX\"],\n",
        "    \"Office Equipment and Services\": [\"XRX\", \"NCR\", \"NTAP\"],\n",
        "    \"Apparel\": [\"VFC\", \"HBI\", \"RL\"],\n",
        "    \"Furniture and Home Furnishings\": [\"MHK\", \"MAS\", \"MLKN\"],\n",
        "    \"Chemicals (General)\": [\"DOW\", \"DD\", \"HUN\"],\n",
        "    \"Electronic Products\": [\"AAPL\", \"HON\", \"DELL\"],\n",
        "    \"Packaging and Containers\": [\"WRK\", \"BALL\", \"CCK\"],\n",
        "    \"Metals and Mining\": [\"AA\", \"FCX\", \"NEM\"],\n",
        "    \"Publishing and Newspapers\": [\"NWSA\", \"RRD\", \"GCI\"],\n",
        "    \"Railroads\": [\"UNP\", \"CSX\", \"NSC\"],\n",
        "    \"Hospitals and Healthcare Services\": [\"UNH\", \"HCA\", \"THC\"],\n",
        "    \"Paper and Forest Products\": [\"WY\", \"IP\", \"BCC\"],\n",
        "    \"Steel\": [\"NUE\", \"X\", \"STLD\"],\n",
        "    \"Investment and Asset Management\": [\"BLK\", \"SCHW\", \"BEN\"],\n",
        "    \"Telecommunications\": [\"T\", \"VZ\", \"CMCSA\"],\n",
        "    \"Agricultural Processing\": [\"ADM\", \"TSN\", \"CHSCP\"],\n",
        "    \"Petroleum\": [\"XOM\", \"CVX\", \"VLO\"],\n",
        "    \"Insurance\": [\"MET\", \"PRU\", \"TRV\"],\n",
        "    \"Food Retailing\": [\"KR\", \"ACI\", \"PUSHX\"],\n",
        "    \"Trucking and Logistics\": [\"XPO\", \"CHRW\", \"JBHT\"],\n",
        "    \"Hotels and Casinos\": [\"MAR\", \"LVS\", \"MGM\"],\n",
        "    \"Motor Vehicle Parts\": [\"GM\", \"F\", \"LEA\"],\n",
        "    \"Electrical Power\": [\"EXC\", \"DUK\", \"PCG\"],\n",
        "    \"Motor Vehicles\": [\"GM\", \"F\", \"PCAR\"],\n",
        "    \"Airlines\": [\"AAL\", \"DAL\", \"UAL\"],\n",
        "}\n",
        "\n",
        "\n",
        "    # ... add other sectors from your list\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Orchestrator: fetch, compute ROCE, compare to BEA sector\n",
        "# -----------------------------\n",
        "def run_sector_roce_analysis(industry_companies: Dict[str, List[str]], years: List[int]=HIST_YEARS):\n",
        "    summary_rows = []\n",
        "    # 1) Get BEA sector data placeholder: user must provide TableID mapping. Here we expect you to set mapping\n",
        "    # Example BEA mapping for 'Steel' must be discovered via BEA GetParameterValues.\n",
        "    BEA_TABLE_MAP = {\n",
        "        # \"Steel\": \"YOUR_TABLE_ID_FOR_STEEL_VALUE_ADDED\",  # << you will need to fill these\n",
        "    }\n",
        "\n",
        "    # for each industry:\n",
        "    for industry, tickers in industry_companies.items():\n",
        "        logging.info(f\"Processing industry {industry} with tickers {tickers}\")\n",
        "        # 1) fetch BEA industry macro (user must fill TableID)\n",
        "        bea_df = None\n",
        "        tableid = BEA_TABLE_MAP.get(industry)\n",
        "        if tableid:\n",
        "            try:\n",
        "                bea_df = bea_get_data(\"GDPbyIndustry\", tableid, years[0], years[-1])\n",
        "            except Exception as e:\n",
        "                logging.warning(f\"BEA fetch failed for {industry}: {e}\")\n",
        "        else:\n",
        "            logging.info(f\"No BEA TableID configured for {industry} — skipping BEA step.\")\n",
        "\n",
        "        # 2) compute company ROCE time series\n",
        "        company_roces = {}\n",
        "        for t in tickers:\n",
        "            try:\n",
        "                fin = fetch_financials_yf(t, years)\n",
        "                roce = compute_roce_from_financials(fin)\n",
        "                company_roces[t] = roce\n",
        "            except Exception as e:\n",
        "                logging.warning(f\"Failed financials for {t}: {e}\")\n",
        "                company_roces[t] = pd.Series({y:np.nan for y in years})\n",
        "        # 3) compute sector average ROCE across companies (simple mean, year by year)\n",
        "        roce_df = pd.DataFrame(company_roces)\n",
        "        sector_mean = roce_df.mean(axis=1, skipna=True)  # index = Year\n",
        "        # 4) For each company, do Big-3 comparing company's ROCE vector to sector_mean vector\n",
        "        for t in tickers:\n",
        "            comp_series = roce_df[t]\n",
        "            # align years\n",
        "            comp_vals = comp_series.reindex(years).values.astype(float)\n",
        "            sector_vals = sector_mean.reindex(years).values.astype(float)\n",
        "            # remove nan pairs\n",
        "            mask = ~np.isnan(comp_vals) & ~np.isnan(sector_vals)\n",
        "            if mask.sum() < 2:\n",
        "                p_val = None; d = None; ci_mean = (None,None,None)\n",
        "            else:\n",
        "                try:\n",
        "                    # paired t-test\n",
        "                    tstat, p_val = stats.ttest_rel(comp_vals[mask], sector_vals[mask])\n",
        "                except Exception:\n",
        "                    p_val = None\n",
        "                d = cohens_d(comp_vals[mask], sector_vals[mask])\n",
        "                ci_mean = bootstrap_ci_diff(comp_vals[mask], sector_vals[mask])\n",
        "            # record\n",
        "            summary_rows.append({\n",
        "                \"industry\": industry,\n",
        "                \"ticker\": t,\n",
        "                \"company_avg_roce\": float(np.nanmean(comp_vals)) if np.nanmean(comp_vals)==np.nanmean(comp_vals) else None,\n",
        "                \"sector_avg_roce\": float(np.nanmean(sector_vals)) if np.nanmean(sector_vals)==np.nanmean(sector_vals) else None,\n",
        "                \"p_value\": p_val,\n",
        "                \"effect_size_d\": d,\n",
        "                \"ci_mean_diff\": ci_mean,\n",
        "                \"n_years\": int(mask.sum())\n",
        "            })\n",
        "    df_summary = pd.DataFrame(summary_rows)\n",
        "    # Save results\n",
        "    df_summary.to_csv(OUTPUT_DIR / \"sector_roce_summary.csv\", index=False)\n",
        "    df_summary.to_json(OUTPUT_DIR / \"sector_roce_summary.json\", orient=\"records\")\n",
        "    logging.info(f\"Wrote {len(df_summary)} summary rows to {OUTPUT_DIR}\")\n",
        "    return df_summary\n",
        "\n",
        "# -----------------------------\n",
        "# 6) Example run\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # run for Steel + sample industries\n",
        "    df_out = run_sector_roce_analysis({\"Steel\": [\"NUE\",\"X\",\"STLD\"], \"Semiconductors\":[\"INTC\",\"QCOM\",\"TXN\"], \"Pharmaceuticals\":[\"PFE\",\"JNJ\",\"MRK\"]})\n",
        "    print(df_out.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDEmnABFBkI3",
        "outputId": "1a6bbd0b-5cd4-4c7a-b079-b9010cd812f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-567894732.py:289: RuntimeWarning: Mean of empty slice\n",
            "  \"company_avg_roce\": float(np.nanmean(comp_vals)) if np.nanmean(comp_vals)==np.nanmean(comp_vals) else None,\n",
            "/tmp/ipython-input-567894732.py:290: RuntimeWarning: Mean of empty slice\n",
            "  \"sector_avg_roce\": float(np.nanmean(sector_vals)) if np.nanmean(sector_vals)==np.nanmean(sector_vals) else None,\n",
            "/tmp/ipython-input-567894732.py:289: RuntimeWarning: Mean of empty slice\n",
            "  \"company_avg_roce\": float(np.nanmean(comp_vals)) if np.nanmean(comp_vals)==np.nanmean(comp_vals) else None,\n",
            "/tmp/ipython-input-567894732.py:290: RuntimeWarning: Mean of empty slice\n",
            "  \"sector_avg_roce\": float(np.nanmean(sector_vals)) if np.nanmean(sector_vals)==np.nanmean(sector_vals) else None,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          industry ticker company_avg_roce sector_avg_roce p_value  \\\n",
            "0            Steel    NUE             None            None    None   \n",
            "1            Steel      X             None            None    None   \n",
            "2            Steel   STLD             None            None    None   \n",
            "3   Semiconductors   INTC             None            None    None   \n",
            "4   Semiconductors   QCOM             None            None    None   \n",
            "5   Semiconductors    TXN             None            None    None   \n",
            "6  Pharmaceuticals    PFE             None            None    None   \n",
            "7  Pharmaceuticals    JNJ             None            None    None   \n",
            "8  Pharmaceuticals    MRK             None            None    None   \n",
            "\n",
            "  effect_size_d        ci_mean_diff  n_years  \n",
            "0          None  (None, None, None)        0  \n",
            "1          None  (None, None, None)        0  \n",
            "2          None  (None, None, None)        0  \n",
            "3          None  (None, None, None)        0  \n",
            "4          None  (None, None, None)        0  \n",
            "5          None  (None, None, None)        0  \n",
            "6          None  (None, None, None)        0  \n",
            "7          None  (None, None, None)        0  \n",
            "8          None  (None, None, None)        0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-567894732.py:289: RuntimeWarning: Mean of empty slice\n",
            "  \"company_avg_roce\": float(np.nanmean(comp_vals)) if np.nanmean(comp_vals)==np.nanmean(comp_vals) else None,\n",
            "/tmp/ipython-input-567894732.py:290: RuntimeWarning: Mean of empty slice\n",
            "  \"sector_avg_roce\": float(np.nanmean(sector_vals)) if np.nanmean(sector_vals)==np.nanmean(sector_vals) else None,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0550289",
        "outputId": "3f5cf07a-5f7a-46d3-a3f1-ecc29aecc58d"
      },
      "source": [
        "# Iterate through the INDUSTRY_COMPANIES dictionary and print the mapping\n",
        "print(\"Industries and their corresponding companies:\")\n",
        "for industry, companies in INDUSTRY_COMPANIES.items():\n",
        "    print(f\"\\nIndustry: {industry}\")\n",
        "    print(\"Companies:\", \", \".join(companies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Industries and their corresponding companies:\n",
            "\n",
            "Industry: Steel\n",
            "Companies: NUE, X, STLD\n",
            "\n",
            "Industry: Semiconductors\n",
            "Companies: INTC, QCOM, TXN\n",
            "\n",
            "Industry: Pharmaceuticals\n",
            "Companies: PFE, JNJ, MRK\n",
            "\n",
            "Industry: Tobacco\n",
            "Companies: MO, PM, BTI\n",
            "\n",
            "Industry: Computer Software\n",
            "Companies: MSFT, ORCL, CRM\n",
            "\n",
            "Industry: Household and Personal Care Products\n",
            "Companies: PG, KMB, CL\n",
            "\n",
            "Industry: Entertainment\n",
            "Companies: DIS, WBD, PARA\n",
            "\n",
            "Industry: Aerospace and Defense\n",
            "Companies: BA, LMT, RTX\n",
            "\n",
            "Industry: Beverages\n",
            "Companies: KO, STZ, PEP\n",
            "\n",
            "Industry: Chemicals (Specialty)\n",
            "Companies: PPG, LIN, BAYRY\n",
            "\n",
            "Industry: Food Processing\n",
            "Companies: KHC, GIS, CAG\n",
            "\n",
            "Industry: Medical Products\n",
            "Companies: BDX, SYK, BSX\n",
            "\n",
            "Industry: Engineering and Construction\n",
            "Companies: FLR, ACM, J\n",
            "\n",
            "Industry: Restaurants and Catering\n",
            "Companies: MCD, DRI, SBUX\n",
            "\n",
            "Industry: Office Equipment and Services\n",
            "Companies: XRX, NCR, NTAP\n",
            "\n",
            "Industry: Apparel\n",
            "Companies: VFC, HBI, RL\n",
            "\n",
            "Industry: Furniture and Home Furnishings\n",
            "Companies: MHK, MAS, MLKN\n",
            "\n",
            "Industry: Chemicals (General)\n",
            "Companies: DOW, DD, HUN\n",
            "\n",
            "Industry: Electronic Products\n",
            "Companies: AAPL, HON, DELL\n",
            "\n",
            "Industry: Packaging and Containers\n",
            "Companies: WRK, BALL, CCK\n",
            "\n",
            "Industry: Metals and Mining\n",
            "Companies: AA, FCX, NEM\n",
            "\n",
            "Industry: Publishing and Newspapers\n",
            "Companies: NWSA, RRD, GCI\n",
            "\n",
            "Industry: Railroads\n",
            "Companies: UNP, CSX, NSC\n",
            "\n",
            "Industry: Hospitals and Healthcare Services\n",
            "Companies: UNH, HCA, THC\n",
            "\n",
            "Industry: Paper and Forest Products\n",
            "Companies: WY, IP, BCC\n",
            "\n",
            "Industry: Investment and Asset Management\n",
            "Companies: BLK, SCHW, BEN\n",
            "\n",
            "Industry: Telecommunications\n",
            "Companies: T, VZ, CMCSA\n",
            "\n",
            "Industry: Agricultural Processing\n",
            "Companies: ADM, TSN, CHSCP\n",
            "\n",
            "Industry: Petroleum\n",
            "Companies: XOM, CVX, VLO\n",
            "\n",
            "Industry: Insurance\n",
            "Companies: MET, PRU, TRV\n",
            "\n",
            "Industry: Food Retailing\n",
            "Companies: KR, ACI, PUSHX\n",
            "\n",
            "Industry: Trucking and Logistics\n",
            "Companies: XPO, CHRW, JBHT\n",
            "\n",
            "Industry: Hotels and Casinos\n",
            "Companies: MAR, LVS, MGM\n",
            "\n",
            "Industry: Motor Vehicle Parts\n",
            "Companies: GM, F, LEA\n",
            "\n",
            "Industry: Electrical Power\n",
            "Companies: EXC, DUK, PCG\n",
            "\n",
            "Industry: Motor Vehicles\n",
            "Companies: GM, F, PCAR\n",
            "\n",
            "Industry: Airlines\n",
            "Companies: AAL, DAL, UAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3NDYrNpOBkNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uoqbxjKNBkRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "bea_sector_roce_workflow.py\n",
        "\n",
        "- Uses BEA API to find relevant industry table IDs (by keyword) and pull annual series (2010-2016)\n",
        "- Fetches company financials via yfinance and computes ROCE (EBIT / (TotalAssets - CurrentLiabilities))\n",
        "- Compares company ROCE to sector ROCE (2010-2016): p-value (paired t), Cohen's d, bootstrap CI\n",
        "- Exports CSV/JSON + Altair charts in dashboard_output/\n",
        "\n",
        "Requirements:\n",
        "  pip install yfinance pandas numpy scipy requests altair\n",
        "\n",
        "Usage:\n",
        "  - Set BEA_USERID env var (recommended). If not set, the script uses the default key embedded below.\n",
        "  - Run: python bea_sector_roce_workflow.py\n",
        "\"\"\"\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from scipy import stats\n",
        "import altair as alt\n",
        "\n",
        "# ---------- Configuration ----------\n",
        "# Prefer env variable; fallback to key you provided (rotate key as needed)\n",
        "BEA_USERID = os.getenv(\"BEA_USERID\", \"C7AB3527-B334-4396-B1C9-837FAF4FB814\")\n",
        "BEA_BASE = \"https://apps.bea.gov/api/data\"\n",
        "BEA_PARAM_BASE = \"https://apps.bea.gov/api/parametervalues\"\n",
        "\n",
        "OUTPUT_DIR = Path(\"dashboard_output\")\n",
        "CHARTS_DIR = OUTPUT_DIR / \"charts\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CHARTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "YEARS = list(range(2018, 2024))   # Updated to 2018-2023 inclusive\n",
        "BOOTSTRAP_ITERS = 2000\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\n",
        "\n",
        "# ---------- Helper: BEA API ----------\n",
        "def bea_get_parameter_values(param_name: str, datasetname: str = \"GDPbyIndustry\") -> List[Dict[str,str]]:\n",
        "    \"\"\"\n",
        "    Return list of parameter values for a BEA parameter (useful to discover TableIDs or Industry codes).\n",
        "    param_name examples: \"TableID\", \"Industry\"\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"UserID\": BEA_USERID,\n",
        "        \"method\": \"GetParameterValues\",\n",
        "        \"DatasetName\": datasetname,\n",
        "        \"ParameterName\": param_name,\n",
        "        \"ResultFormat\": \"JSON\"\n",
        "    }\n",
        "    r = requests.get(BEA_PARAM_BASE, params=params, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    j = r.json()\n",
        "    return j.get(\"BEAAPI\", {}).get(\"Results\", {}).get(\"ParamValue\", [])\n",
        "\n",
        "def bea_get_data(dataset: str, tableid: str, year_from: int, year_to: int, frequency: str = \"A\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Fetch BEA data for a specific TableID and year range.\n",
        "    Returns DataFrame with at least Year and DataValue (numeric).\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"UserID\": BEA_USERID,\n",
        "        \"method\": \"GetData\",\n",
        "        \"DataSetName\": dataset,\n",
        "        \"TableID\": tableid,\n",
        "        \"Frequency\": frequency,\n",
        "        \"Year\": f\"{year_from}-{year_to}\",\n",
        "        \"ResultFormat\": \"JSON\"\n",
        "    }\n",
        "    r = requests.get(BEA_BASE, params=params, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    j = r.json()\n",
        "    data = j.get(\"BEAAPI\", {}).get(\"Results\", {}).get(\"Data\", [])\n",
        "    if not data:\n",
        "        return pd.DataFrame()\n",
        "    df = pd.DataFrame(data)\n",
        "    # Normalize\n",
        "    if \"DataValue\" in df.columns:\n",
        "        df[\"DataValue\"] = pd.to_numeric(df[\"DataValue\"], errors=\"coerce\")\n",
        "    if \"TimePeriod\" in df.columns:\n",
        "        df[\"Year\"] = df[\"TimePeriod\"].astype(int)\n",
        "    return df\n",
        "\n",
        "# ---------- Financials & ROCE ----------\n",
        "def fetch_financials_yf(ticker: str, years: List[int]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Attempt to extract annual EBIT and balance-sheet items from yfinance.\n",
        "    Returns DataFrame indexed by Year with columns ['EBIT','TotalAssets','CurrentLiabilities'] (may contain Nones).\n",
        "    \"\"\"\n",
        "    tk = yf.Ticker(ticker)\n",
        "    # yfinance returns DataFrames with DatetimeIndex for .financials and .balance_sheet\n",
        "    out_rows = []\n",
        "    try:\n",
        "        inc = tk.financials.transpose()  # may be empty\n",
        "        if inc.empty:\n",
        "            logging.warning(f\"yfinance: No income statement data for {ticker}\")\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"yfinance: Error fetching income statement for {ticker}: {e}\")\n",
        "        inc = pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        bal = tk.balance_sheet.transpose()\n",
        "        if bal.empty:\n",
        "             logging.warning(f\"yfinance: No balance sheet data for {ticker}\")\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"yfinance: Error fetching balance sheet for {ticker}: {e}\")\n",
        "        bal = pd.DataFrame()\n",
        "\n",
        "    # Normalize yearly index to ints if possible\n",
        "    def to_year_index(df):\n",
        "        if df is None or df.empty:\n",
        "            return pd.DataFrame()\n",
        "        if isinstance(df.index, pd.DatetimeIndex):\n",
        "            df2 = df.copy()\n",
        "            df2.index = df2.index.year\n",
        "            return df2\n",
        "        else:\n",
        "            return df\n",
        "\n",
        "    inc = to_year_index(inc)\n",
        "    bal = to_year_index(bal)\n",
        "\n",
        "    for y in years:\n",
        "        row = {\"Year\": y, \"EBIT\": None, \"TotalAssets\": None, \"CurrentLiabilities\": None}\n",
        "        if not inc.empty and y in inc.index:\n",
        "            # Try common names\n",
        "            for key in [\"Operating Income\", \"OperatingIncome\", \"OperatingIncomeLoss\", \"Ebit\", \"Earnings before interest and taxes\", \"EarningsBeforeInterestAndTaxes\"]:\n",
        "                if key in inc.columns:\n",
        "                    val = inc.loc[y, key]\n",
        "                    row[\"EBIT\"] = float(val) if pd.notnull(val) else None\n",
        "                    break\n",
        "            # fallback to Net Income\n",
        "            if row[\"EBIT\"] is None and \"Net Income\" in inc.columns:\n",
        "                val = inc.loc[y, \"Net Income\"]\n",
        "                row[\"EBIT\"] = float(val) if pd.notnull(val) else None\n",
        "        if not bal.empty and y in bal.index:\n",
        "            # Total assets\n",
        "            for key in [\"Total Assets\", \"TotalAssets\",\"Assets\"]:\n",
        "                if key in bal.columns:\n",
        "                    val = bal.loc[y, key]\n",
        "                    row[\"TotalAssets\"] = float(val) if pd.notnull(val) else None\n",
        "                    break\n",
        "            for key in [\"Total Current Liabilities\", \"Current Liabilities\", \"TotalCurrentLiabilities\",\"CurrentLiabilities\"]:\n",
        "                if key in bal.columns:\n",
        "                    val = bal.loc[y, key]\n",
        "                    row[\"CurrentLiabilities\"] = float(val) if pd.notnull(val) else None\n",
        "                    break\n",
        "        if row[\"EBIT\"] is None or row[\"TotalAssets\"] is None or row[\"CurrentLiabilities\"] is None:\n",
        "             logging.info(f\"yfinance: Missing data for {ticker} in year {y} (EBIT: {row['EBIT']}, TA: {row['TotalAssets']}, CL: {row['CurrentLiabilities']})\")\n",
        "        out_rows.append(row)\n",
        "    dfout = pd.DataFrame(out_rows).set_index(\"Year\")\n",
        "    return dfout\n",
        "\n",
        "def compute_roce(fin_df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    ROCE (%) = EBIT / (TotalAssets - CurrentLiabilities) * 100\n",
        "    Returns pd.Series indexed by Year (floats or NaN)\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    for year, row in fin_df.iterrows():\n",
        "        ebit = row.get(\"EBIT\")\n",
        "        ta = row.get(\"TotalAssets\")\n",
        "        cl = row.get(\"CurrentLiabilities\")\n",
        "        if ebit is None or ta is None or cl is None:\n",
        "            out[int(year)] = np.nan\n",
        "            continue\n",
        "        denom = ta - cl\n",
        "        if denom is None or denom == 0:\n",
        "            out[int(year)] = np.nan\n",
        "            continue\n",
        "        out[int(year)] = (float(ebit) / float(denom)) * 100.0\n",
        "    return pd.Series(out)\n",
        "\n",
        "# ---------- Big-3 stats ----------\n",
        "def cohens_d(a: np.ndarray, b: np.ndarray) -> Optional[float]:\n",
        "    a = np.array(a); b = np.array(b)\n",
        "    a = a[~np.isnan(a)]; b = b[~np.isnan(b)]\n",
        "    if len(a) < 2 or len(b) < 2:\n",
        "        return None\n",
        "    na, nb = len(a), len(b)\n",
        "    sa = a.std(ddof=1); sb = b.std(ddof=1)\n",
        "    pooled = math.sqrt(((na-1)*sa*sa + (nb-1)*sb*sb) / (na+nb-2)) if na+nb-2>0 else None\n",
        "    if pooled and pooled > 0:\n",
        "        return float((a.mean() - b.mean()) / pooled)\n",
        "    return None\n",
        "\n",
        "def bootstrap_diff_ci(a: np.ndarray, b: np.ndarray, iters:int=BOOTSTRAP_ITERS, ci:float=95.0):\n",
        "    a = np.array(a); b = np.array(b)\n",
        "    a = a[~np.isnan(a)]; b = b[~np.isnan(b)]\n",
        "    if len(a) < 2 or len(b) < 2:\n",
        "        return None, None, None\n",
        "    rng = np.random.default_rng(12345)\n",
        "    diffs = []\n",
        "    for _ in range(iters):\n",
        "        sa = rng.choice(a, size=len(a), replace=True)\n",
        "        sb = rng.choice(b, size=len(b), replace=True)\n",
        "        diffs.append(np.mean(sa) - np.mean(sb))\n",
        "    arr = np.array(diffs)\n",
        "    low = np.percentile(arr, (100-ci)/2)\n",
        "    high = np.percentile(arr, 100-(100-ci)/2)\n",
        "    return float(arr.mean()), float(low), float(high)\n",
        "\n",
        "# ---------- High-level orchestrator ----------\n",
        "# Map industries to tickers (include Nucor, US Steel, Steel Dynamics)\n",
        "INDUSTRY_COMPANIES = {\n",
        "    \"Steel\": [\"NUE\", \"X\", \"STLD\"],   # Nucor (NUE), U.S. Steel (X), Steel Dynamics (STLD)\n",
        "    \"Tobacco\": [\"MO\", \"RAI\", \"PM\"],  # Altria, Reynolds American, Philip Morris Intl.\n",
        "    \"Computer Software\": [\"MSFT\", \"ORCL\", \"CRM\"],\n",
        "    \"Pharmaceuticals\": [\"PFE\", \"JNJ\", \"MRK\"],\n",
        "    # Add other industries/topics as needed...\n",
        "}\n",
        "\n",
        "def run_workflow(industry_companies: Dict[str, List[str]], years: List[int]=YEARS):\n",
        "    results = []\n",
        "    # Optionally: discover candidate TableIDs for GDPbyIndustry (user may later refine)\n",
        "    # We'll attempt to find TableIDs whose descriptions contain the industry name (case-insensitive)\n",
        "    logging.info(\"Fetching BEA TableIDs metadata (may be large)...\")\n",
        "    try:\n",
        "        paramvals = bea_get_parameter_values(\"TableID\")\n",
        "        # paramvals is list of dicts with 'ParameterValue' and maybe 'Description'\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Could not fetch TableID parameter list from BEA: {e}\")\n",
        "        paramvals = []\n",
        "\n",
        "    # build a simple mapping candidate: find TableIDs where description or value contains industry keyword\n",
        "    tableid_candidates = {}\n",
        "    for industry in industry_companies.keys():\n",
        "        candidates = []\n",
        "        key = industry.lower()\n",
        "        for p in paramvals:\n",
        "            pv = str(p.get(\"ParameterValue\",\"\"))\n",
        "            desc = str(p.get(\"Description\",\"\") or \"\")\n",
        "            if key in pv.lower() or key in desc.lower():\n",
        "                candidates.append({\"TableID\": pv, \"Description\": desc})\n",
        "        tableid_candidates[industry] = candidates\n",
        "\n",
        "    # Save candidate TableIDs for review\n",
        "    with open(OUTPUT_DIR / \"bea_tableid_candidates.json\",\"w\") as fh:\n",
        "        json.dump(tableid_candidates, fh, indent=2)\n",
        "    logging.info(\"Wrote BEA TableID candidate list to dashboard_output/bea_tableid_candidates.json\")\n",
        "\n",
        "    # NOTE: The candidate list is for human review. Automated mapping risk: false positives.\n",
        "    # For demo, we attempt to use frequently useful table: \"GDPbyIndustry\" TableID \"A... something\".\n",
        "    # However, because BEA table IDs vary, you should choose the appropriate TableID from the candidate file.\n",
        "    # For this script, we will not auto-call an arbitrary TableID; instead we will proceed with company ROCE computation\n",
        "    # and write a results file to be merged with BEA series once you pick exact TableIDs.\n",
        "\n",
        "    # 1) compute ROCE for each company\n",
        "    for industry, tickers in industry_companies.items():\n",
        "        logging.info(f\"Processing industry {industry} tickers: {tickers}\")\n",
        "        # compute company-level ROCE time series\n",
        "        company_roce = {}\n",
        "        for t in tickers:\n",
        "            try:\n",
        "                fin = fetch_financials_yf(t, years)\n",
        "                roce_series = compute_roce(fin)\n",
        "                company_roce[t] = roce_series.reindex(years)\n",
        "                logging.info(f\"Fetched ROCE for {t}: available years {list(company_roce[t].dropna().index)}\")\n",
        "            except Exception as e:\n",
        "                logging.warning(f\"Error computing ROCE for {t}: {e}\")\n",
        "                company_roce[t] = pd.Series({y:np.nan for y in years})\n",
        "\n",
        "        # compute sector mean (simple mean across companies each year)\n",
        "        roce_df = pd.DataFrame(company_roce)\n",
        "        sector_mean = roce_df.mean(axis=1, skipna=True)\n",
        "\n",
        "        # per-company big-3 vs sector mean\n",
        "        for t in tickers:\n",
        "            a = company_roce[t].values\n",
        "            b = sector_mean.values\n",
        "            # mask pairs\n",
        "            valid = ~np.isnan(a) & ~np.isnan(b)\n",
        "            n_pairs = int(np.sum(valid))\n",
        "            if n_pairs >= 2:\n",
        "                # paired t-test (year-over-year comparison)\n",
        "                try:\n",
        "                    tstat, p_val = stats.ttest_rel(a[valid], b[valid])\n",
        "                except Exception:\n",
        "                    tstat, p_val = None, None\n",
        "                d = cohens_d(a[valid], b[valid])\n",
        "                mean_diff, low_ci, high_ci = bootstrap_diff_ci(a[valid], b[valid])\n",
        "            else:\n",
        "                tstat, p_val, d, mean_diff, low_ci, high_ci = (None, None, None, None, None, None)\n",
        "\n",
        "            results.append({\n",
        "                \"industry\": industry,\n",
        "                \"ticker\": t,\n",
        "                \"company_mean_roce\": float(np.nanmean(a)) if not np.isnan(np.nanmean(a)) else None,\n",
        "                \"sector_mean_roce\": float(np.nanmean(b)) if not np.isnan(np.nanmean(b)) else None,\n",
        "                \"n_years\": n_pairs,\n",
        "                \"t_stat\": tstat,\n",
        "                \"p_value\": p_val,\n",
        "                \"cohens_d\": d,\n",
        "                \"mean_diff\": mean_diff,\n",
        "                \"ci_low\": low_ci,\n",
        "                \"ci_high\": high_ci\n",
        "            })\n",
        "\n",
        "        # produce a simple sector time-series chart (company lines + sector mean)\n",
        "        ts_df = roce_df.reset_index().rename(columns={'index': 'Year'}).melt(id_vars=\"Year\", var_name=\"Ticker\", value_name=\"ROCE\")\n",
        "        # add sector mean series\n",
        "        sector_mean_df = sector_mean.reset_index().rename(columns={0:\"ROCE\"})\n",
        "        sector_mean_df[\"Ticker\"] = f\"{industry} (Sector Mean)\"\n",
        "        ts_all = pd.concat([ts_df, sector_mean_df], ignore_index=True, sort=False)\n",
        "        try:\n",
        "            chart = alt.Chart(ts_all).mark_line().encode(\n",
        "                x=alt.X(\"Year:O\"),\n",
        "                y=alt.Y(\"ROCE:Q\"),\n",
        "                color=alt.Color(\"Ticker:N\"),\n",
        "                tooltip=[\"Year\",\"Ticker\",\"ROCE\"]\n",
        "            ).properties(width=800, height=350, title=f\"{industry} ROCE (company lines + sector mean)\")\n",
        "            chart.save(CHARTS_DIR / f\"{industry}_roce_timeseries.html\")\n",
        "            logging.info(f\"Wrote chart for industry {industry}\")\n",
        "        except Exception as e:\n",
        "            logging.warning(f\"Could not write chart for {industry}: {e}\")\n",
        "\n",
        "    # save results\n",
        "    dfres = pd.DataFrame(results)\n",
        "    dfres.to_csv(OUTPUT_DIR / \"sector_roce_summary.csv\", index=False)\n",
        "    dfres.to_json(OUTPUT_DIR / \"sector_roce_summary.json\", orient=\"records\", double_precision=6)\n",
        "    logging.info(\"Wrote sector_roce_summary.csv and .json to dashboard_output/\")\n",
        "    return dfres\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Starting BEA + Sector ROCE workflow\")\n",
        "    df = run_workflow(INDUSTRY_COMPANIES)\n",
        "    print(df.head(12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmcJN4d2AHwA",
        "outputId": "d3064679-1227-4e87-ae31-3480ac9ad51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Could not fetch TableID parameter list from BEA: Expecting value: line 1 column 1 (char 0)\n",
            "WARNING:root:yfinance: No income statement data for X\n",
            "WARNING:root:yfinance: No balance sheet data for X\n",
            "/tmp/ipython-input-3156730679.py:298: RuntimeWarning: Mean of empty slice\n",
            "  \"company_mean_roce\": float(np.nanmean(a)) if not np.isnan(np.nanmean(a)) else None,\n",
            "WARNING:root:yfinance: No income statement data for RAI\n",
            "WARNING:root:yfinance: No balance sheet data for RAI\n",
            "/tmp/ipython-input-3156730679.py:298: RuntimeWarning: Mean of empty slice\n",
            "  \"company_mean_roce\": float(np.nanmean(a)) if not np.isnan(np.nanmean(a)) else None,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             industry ticker  company_mean_roce  sector_mean_roce  n_years  \\\n",
            "0               Steel    NUE          34.226283         36.854123        3   \n",
            "1               Steel      X                NaN         36.854123        0   \n",
            "2               Steel   STLD          39.481963         36.854123        3   \n",
            "3             Tobacco     MO          40.596899         41.288273        3   \n",
            "4             Tobacco    RAI                NaN         41.288273        0   \n",
            "5             Tobacco     PM          41.979647         41.288273        3   \n",
            "6   Computer Software   MSFT          29.833842         15.494479        2   \n",
            "7   Computer Software   ORCL          15.003071         15.494479        2   \n",
            "8   Computer Software    CRM           1.646526         15.494479        2   \n",
            "9     Pharmaceuticals    PFE          13.635835         14.755275        3   \n",
            "10    Pharmaceuticals    JNJ          16.860865         14.755275        3   \n",
            "11    Pharmaceuticals    MRK          13.769124         14.755275        3   \n",
            "\n",
            "        t_stat   p_value   cohens_d  mean_diff     ci_low    ci_high  \n",
            "0    -2.140688  0.165634  -0.216798  -2.755291 -18.090931  12.841242  \n",
            "1          NaN       NaN        NaN        NaN        NaN        NaN  \n",
            "2     2.140688  0.165634   0.237279   2.494174 -10.894783  15.979923  \n",
            "3    -0.136131  0.904184  -0.147608  -0.743310  -7.523802   4.620924  \n",
            "4          NaN       NaN        NaN        NaN        NaN        NaN  \n",
            "5     0.136131  0.904184   0.061251   0.699609 -12.214847  16.938035  \n",
            "6   101.143917  0.006294  10.058341  14.336262  12.328223  16.350502  \n",
            "7    -0.290249  0.820163  -0.176194  -0.487529  -4.053833   3.071015  \n",
            "8    -7.547273  0.083862 -10.671566 -13.859949 -15.682782 -12.013125  \n",
            "9    -0.405091  0.724632  -0.127613  -1.169661 -12.392189  10.098535  \n",
            "10    0.461032  0.690055   0.464257   1.968720  -3.627433   8.203119  \n",
            "11   -0.518143  0.655981  -0.126956  -1.045276 -11.107506   8.990873  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ BEA API: Dynamic Parameter Discovery\n",
        "\n",
        "BEA provides an endpoint to list all TableIDs and parameters."
      ],
      "metadata": {
        "id": "M0qfz9GQKKRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Load your BEA API key securely\n",
        "BEA_API_KEY = os.getenv(\"BEA_API_KEY\")  # Set in environment variables or .env\n",
        "\n",
        "def get_bea_parameters():\n",
        "    \"\"\"Return all available BEA parameter values for metadata discovery.\"\"\"\n",
        "    url = \"https://apps.bea.gov/api/parametervalues\"\n",
        "    params = {\n",
        "        \"UserID\": BEA_API_KEY,\n",
        "        \"method\": \"GetParameterValues\",\n",
        "        \"methodname\": \"GetData\",\n",
        "        \"ResultFormat\": \"JSON\"\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extract list of parameters\n",
        "    parameters = {}\n",
        "    for item in data['BEAAPI']['Results']['Parameter']:\n",
        "        name = item['ParameterName']\n",
        "        values = [v['Key'] for v in item.get('Values', [])]\n",
        "        parameters[name] = values\n",
        "    return parameters\n",
        "\n",
        "bea_params = get_bea_parameters()\n",
        "print(bea_params.keys())  # List of all parameter names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "VkSDtWFxAHz1",
        "outputId": "2fdeb8e7-9c98-452d-9dca-dd191ca98ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/simplejson/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, allow_nan, **kw)\u001b[0m\n\u001b[1;32m    513\u001b[0m             and not use_decimal and not allow_nan and not kw):\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/simplejson/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/simplejson/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx, _w, _PY3)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-814481638.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mbea_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bea_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbea_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# List of all parameter names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-814481638.py\u001b[0m in \u001b[0;36mget_bea_parameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     }\n\u001b[1;32m     16\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Extract list of parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0;31m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0;31m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What it does:\n",
        "\n",
        "Queries BEA’s API for all available parameters and values.\n",
        "\n",
        "Returns a dictionary: {'TableID': [...], 'Industry': [...], 'GeoFips': [...], 'Frequency': [...], ...}\n",
        "\n",
        "Can be used to dynamically build queries without manually checking BEA documentation."
      ],
      "metadata": {
        "id": "mbgUYmSLKRjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2️⃣ Alpha Vantage: Metadata Discovery\n",
        "*  Alpha Vantage dedicated access key is: 2M31LG9FZQGZX2PJ\n",
        "\n",
        "While Alpha Vantage doesn’t have an explicit “list all symbols” endpoint for all exchanges, you can:\n",
        "\n",
        "Use the sector performance endpoint:"
      ],
      "metadata": {
        "id": "9GfmRjRAKU6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_alpha_vantage_sector(api_key):\n",
        "    url = \"https://www.alphavantage.co/query\"\n",
        "    params = {\n",
        "        \"function\": \"SECTOR\",\n",
        "        \"apikey\": api_key\n",
        "    }\n",
        "    r = requests.get(url, params=params)\n",
        "    return r.json()\n",
        "\n",
        "sector_data = get_alpha_vantage_sector(os.getenv(\"ALPHA_VANTAGE_KEY\"))\n",
        "print(sector_data.keys())  # Gives all sector performance metrics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tF0HCGJAH2r",
        "outputId": "c925433e-9f43-4215-9e77-1470d8da85f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use your symbol lists (download from exchanges or curated CSV):\n",
        "\n",
        "NASDAQ, NYSE, AMEX\n",
        "\n",
        "Map tickers to company names and sectors.\n",
        "\n",
        "Use these tickers dynamically in queries like TIME_SERIES_DAILY_ADJUSTED or OVERVIEW."
      ],
      "metadata": {
        "id": "QVY3QcHsKata"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3️⃣ SEC EDGAR: Parameter Discovery\n",
        "\n",
        "You can query CIK numbers, filings types (10-K, 10-Q, 8-K) via:"
      ],
      "metadata": {
        "id": "I15ZgKmiKhre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://data.sec.gov/submissions/CIK########.json\n"
      ],
      "metadata": {
        "id": "YR51eVFvAH50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4️⃣ Implementation Plan in Your Dashboard\n",
        "\n",
        "#1. Metadata Module:\n",
        "\n",
        "* Queries BEA, Alpha Vantage, EDGAR for available parameters.\n",
        "* Stores in cache (JSON or DB table) for fast lookup.\n",
        "* Provides dropdowns/filters in dashboard frontend to select TableIDs, tickers, or filings.\n",
        "\n",
        "#2. Dynamic Query Builder:\n",
        "\n",
        "* User selects parameters (or default top-performing sectors).\n",
        "* The backend constructs API queries automatically.\n",
        "* ETL pulls, transforms, and stores the results.\n",
        "\n",
        "#3. Interactive Dashboard:\n",
        "\n",
        "* Let users explore all available datasets without needing API documentation.\n",
        "* Show metadata summaries, e.g., “100+ TableIDs available for BEA GDP by Industry”."
      ],
      "metadata": {
        "id": "KEuQ5ZJXKpsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dynamic SEC EDGAR crawler that automatically:\n",
        "\n",
        "* Identifies companies from your investment list (tickers or names).\n",
        "\n",
        "* Maps tickers/names to CIK numbers automatically.\n",
        "\n",
        "* Retrieves all available filing types (10-K, 10-Q, 8-K, etc.) for each company.\n",
        "\n",
        "* Stores results in a structured format for your ETL/EDA pipeline.\n",
        "\n",
        "Here’s a Python implementation outline:"
      ],
      "metadata": {
        "id": "wzzhi1Bk4iiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1️⃣ Setup"
      ],
      "metadata": {
        "id": "k9bsMlH34jAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Base URL for SEC EDGAR\n",
        "EDGAR_CIK_BASE = \"https://www.sec.gov/files/company_tickers.json\"  # Up-to-date ticker→CIK mapping\n",
        "EDGAR_SUBMISSIONS = \"https://data.sec.gov/submissions/CIK{}.json\"  # Replace {} with 10-digit CIK\n",
        "HEADERS = {\"User-Agent\": \"WhitneyMoss-DataAnalyticsApp\"}\n",
        "\n",
        "# Example: List of investments to research\n",
        "investments = [\"AAPL\", \"MSFT\", \"NUE\", \"XOM\"]  # Apple, Microsoft, Nucor, ExxonMobil\n"
      ],
      "metadata": {
        "id": "hEiMqelW4h3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2️⃣ Fetch CIK Numbers Automatically"
      ],
      "metadata": {
        "id": "ZTRHa5aR4jYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cik_mapping():\n",
        "    \"\"\"Download SEC ticker-to-CIK mapping dynamically.\"\"\"\n",
        "    r = requests.get(EDGAR_CIK_BASE, headers=HEADERS)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    time.sleep(1) # Add a small delay after fetching the mapping\n",
        "    df = pd.DataFrame(data).T  # convert JSON to DataFrame\n",
        "    df['cik_str'] = df['cik_str'].apply(lambda x: str(x).zfill(10))  # pad to 10 digits\n",
        "    return df[['ticker', 'cik_str', 'title']]\n",
        "\n",
        "cik_df = get_cik_mapping()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "cnFPJ5aC4ixj",
        "outputId": "c8dcb315-de2c-45df-fe05-12313a462af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "403 Client Error: Forbidden for url: https://www.sec.gov/files/company_tickers.json",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1724158375.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cik_str'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcik_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cik_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1724158375.py\u001b[0m in \u001b[0;36mget_cik_mapping\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Download SEC ticker-to-CIK mapping dynamically.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEDGAR_CIK_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEADERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add a small delay after fetching the mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.sec.gov/files/company_tickers.json"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "43458d77",
        "outputId": "1cb732b8-3dcb-41e5-e848-90bc252a5fc5"
      },
      "source": [
        "# Retry fetching company tickers from SEC\n",
        "cik_df = get_cik_mapping()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "403 Client Error: Forbidden for url: https://www.sec.gov/files/company_tickers.json",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-361900498.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Retry fetching company tickers from SEC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcik_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cik_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1724158375.py\u001b[0m in \u001b[0;36mget_cik_mapping\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Download SEC ticker-to-CIK mapping dynamically.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEDGAR_CIK_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEADERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add a small delay after fetching the mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.sec.gov/files/company_tickers.json"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3️⃣ Retrieve Filings for Each Company"
      ],
      "metadata": {
        "id": "X39naBmU5OMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_company_filings(ticker, cik_df):\n",
        "    \"\"\"Return all available filing types for a given company ticker.\"\"\"\n",
        "    try:\n",
        "        cik = cik_df.loc[cik_df['ticker'] == ticker.upper(), 'cik_str'].values[0]\n",
        "    except IndexError:\n",
        "        print(f\"Ticker {ticker} not found in SEC mapping.\")\n",
        "        return None\n",
        "\n",
        "    url = EDGAR_SUBMISSIONS.format(cik)\n",
        "    r = requests.get(url, headers=HEADERS)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "\n",
        "    # Extract filings\n",
        "    filings = pd.DataFrame(data['filings']['recent'])\n",
        "    filings['ticker'] = ticker.upper()\n",
        "    return filings[['ticker', 'form', 'filingDate', 'accessionNumber']]\n",
        "\n",
        "# Example usage:\n",
        "all_filings = []\n",
        "for ticker in investments:\n",
        "    df = get_company_filings(ticker, cik_df)\n",
        "    if df is not None:\n",
        "        all_filings.append(df)\n",
        "    time.sleep(0.5)  # SEC rate limit\n",
        "all_filings_df = pd.concat(all_filings, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "3KJNDe6i4jK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4️⃣ Output / Storage"
      ],
      "metadata": {
        "id": "9xn2qje45b9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV for ETL or dashboard integration\n",
        "all_filings_df.to_csv(\"sec_filings_dynamic.csv\", index=False)\n",
        "print(all_filings_df.head())\n"
      ],
      "metadata": {
        "id": "LclqoOTd4joy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}